{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "```json\n{\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Operator Assistant - Data Exploration\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 1. Setup and Data Loading\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import pandas as pd\\n\",\n    \"import numpy as np\\n\",\n    \"import matplotlib.pyplot as plt\\n\",\n    \"import seaborn as sns\\n\",\n    \"from sklearn.model_selection import train_test_split\\n\",\n    \"from sklearn.feature_extraction.text import TfidfVectorizer\\n\",\n    \"from sklearn.naive_bayes import MultinomialNB\\n\",\n    \"from sklearn.linear_model import LogisticRegression\\n\",\n    \"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\",\n    \"from scipy import stats\\n\",\n    \"import random\\n\",\n    \"from datetime import datetime, timedelta\\n\",\n    \"\\n\",\n    \"sns.set_theme(style=\\\"whitegrid\\\")\\n\",\n    \"pd.set_option('display.max_columns', 50)\\n\",\n    \"pd.set_option('display.width', 1000)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Simulate data as no dataset was provided\\n\",\n    \"def generate_synthetic_data(num_records=1000):\\n\",\n    \"    data = []\\n\",\n    \"    intents = ['file_create', 'file_list', 'file_delete', 'web_search', 'other', 'greeting']\\n\",\n    \"    base_commands = {\\n\",\n    \"        'file_create': ['create file {name}.txt', 'make a new document called {name}', 'generate {name}.docx'],\\n\",\n    \"        'file_list': ['list files in documents', 'show me my downloads', 'what files are on the desktop?', 'list directory {dir}'],\\n\",\n    \"        'file_delete': ['delete {name}.txt', 'remove the file {name}.log', 'get rid of {name}.tmp', 'erase {name}.pdf'],\\n\",\n    \"        'web_search': ['search for {query}', 'what is {query}?', 'find information about {query}', 'look up {query} on the web'],\\n\",\n    \"        'other': ['what time is it?', 'set a timer for 5 minutes', 'open calculator', 'tell me a joke'],\\n\",\n    \"        'greeting': ['hello assistant', 'good morning', 'hey operator', 'hi there']\\n\",\n    \"    }\\n\",\n    \"    file_names = ['report', 'notes', 'image', 'backup', 'project_data', 'meeting_minutes', 'draft']\\n\",\n    \"    file_ext = ['txt', 'docx', 'pdf', 'log', 'tmp', 'jpg', 'png']\\n\",\n    \"    search_queries = ['python programming', 'weather today', 'best restaurants near me', 'jupyter notebooks', 'ai assistants', 'natural language processing']\\n\",\n    \"    dirs = ['documents', 'downloads', 'desktop', 'pictures', '/var/log']\\n\",\n    \"    user_ids = [f'user_{i:03d}' for i in range(1, 21)]\\n\",\n    \"    start_date = datetime.now() - timedelta(days=30)\\n\",\n    \"\\n\",\n    \"    for i in range(num_records):\\n\",\n    \"        intent = random.choice(intents)\\n\",\n    \"        user_id = random.choice(user_ids)\\n\",\n    \"        timestamp = start_date + timedelta(seconds=random.randint(0, 30*24*60*60))\\n\",\n    \"        \\n\",\n    \"        command_template = random.choice(base_commands[intent])\\n\",\n    \"        command_text = command_template\\n\",\n    \"        if '{name}' in command_template:\\n\",\n    \"            name = random.choice(file_names)\\n\",\n    \"            ext = random.choice(file_ext)\\n\",\n    \"            command_text = command_template.format(name=f'{name}_{i%10}.{ext}')\\n\",\n    \"        elif '{query}' in command_template:\\n\",\n    \"            query = random.choice(search_queries)\\n\",\n    \"            command_text = command_template.format(query=query)\\n\",\n    \"        elif '{dir}' in command_template:\\n\",\n    \"             dir_name = random.choice(dirs)\\n\",\n    \"             command_text = command_template.format(dir=dir_name)\\n\",\n    \"            \\n\",\n    \"        response_time_ms = max(50, int(np.random.normal(loc=500, scale=300)) + len(command_text) * 5)\\n\",\n    \"        success_prob = 0.9 if intent != 'other' else 0.98\\n\",\n    \"        success = np.random.rand() < success_prob\\n\",\n    \"        \\n\",\n    \"        confirmation_required = False\\n\",\n    \"        confirmation_given = np.nan\\n\",\n    \"        if intent == 'file_delete':\\n\",\n    \"            confirmation_required = True\\n\",\n    \"            if success: # Only ask for confirmation if the initial step might proceed\\n\",\n    \"                 # Simulate user confirmation (more likely to confirm than not)\\n\",\n    \"                 confirmation_given = np.random.rand() < 0.85 \\n\",\n    \"                 success = confirmation_given # Final success depends on confirmation\\n\",\n    \"            else:\\n\",\n    \"                 confirmation_given = False # If initial check failed (e.g. file not found), no confirmation needed/given\\n\",\n    \"                 \\n\",\n    \"        data.append({\\n\",\n    \"            'timestamp': timestamp,\\n\",\n    \"            'user_id': user_id,\\n\",\n    \"            'command_text': command_text,\\n\",\n    \"            'intent': intent,\\n\",\n    \"            'response_time_ms': response_time_ms,\\n\",\n    \"            'success': success,\\n\",\n    \"            'confirmation_required': confirmation_required,\\n\",\n    \"            'confirmation_given': confirmation_given\\n\",\n    \"        })\\n\",\n    \"        \\n\",\n    \"    df = pd.DataFrame(data)\\n\",\n    \"    df['timestamp'] = pd.to_datetime(df['timestamp'])\\n\",\n    \"    # Ensure boolean types where appropriate, handling NaN for confirmation_given\\n\",\n    \"    df['success'] = df['success'].astype(bool)\\n\",\n    \"    df['confirmation_required'] = df['confirmation_required'].astype(bool)\\n\",\n    \"    # Convert confirmation_given to nullable boolean\\n\",\n    \"    df['confirmation_given'] = df['confirmation_given'].map({True: True, False: False, np.nan: pd.NA}).astype('boolean')\\n\",\n    \"    return df.sort_values(by='timestamp').reset_index(drop=True)\\n\",\n    \"\\n\",\n    \"df = generate_synthetic_data(num_records=1500)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 1.1 Data Inspection\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"print(\\\"First 5 rows:\\\")\\n\",\n    \"display(df.head())\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"print(\\\"\\\\nData Info:\\\")\\n\",\n    \"df.info()\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"print(\\\"\\\\nMissing Values:\\\")\\n\",\n    \"print(df.isnull().sum())\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"print(\\\"\\\\nDescriptive Statistics (Numerical):\\\")\\n\",\n    \"display(df.describe())\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"print(\\\"\\\\nDescriptive Statistics (Categorical/Object):\\\")\\n\",\n    \"display(df.describe(include=['object', 'boolean', 'datetime64[ns]']))\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 2. Exploratory Data Analysis (EDA)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 2.1 Intent Distribution\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"plt.figure(figsize=(10, 6))\\n\",\n    \"sns.countplot(data=df, y='intent', order = df['intent'].value_counts().index, palette='viridis')\\n\",\n    \"plt.title('Distribution of Command Intents')\\n\",\n    \"plt.xlabel('Frequency')\\n\",\n    \"plt.ylabel('Intent')\\n\",\n    \"plt.tight_layout()\\n\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 2.2 Response Time Distribution\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"plt.figure(figsize=(12, 5))\\n\",\n    \"\\n\",\n    \"plt.subplot(1, 2, 1)\\n\",\n    \"sns.histplot(df['response_time_ms'], kde=True, bins=30)\\n\",\n    \"plt.title('Distribution of Response Time (ms)')\\n\",\n    \"plt.xlabel('Response Time (ms)')\\n\",\n    \"plt.ylabel('Frequency')\\n\",\n    \"\\n\",\n    \"plt.subplot(1, 2, 2)\\n\",\n    \"sns.boxplot(data=df, x='intent', y='response_time_ms', palette='viridis')\\n\",\n    \"plt.title('Response Time by Intent')\\n\",\n    \"plt.xlabel('Intent')\\n\",\n    \"plt.ylabel('Response Time (ms)')\\n\",\n    \"plt.xticks(rotation=45, ha='right')\\n\",\n    \"\\n\",\n    \"plt.tight_layout()\\n\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 2.3 Success Rate Analysis\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"plt.figure(figsize=(10, 6))\\n\",\n    \"success_rate = df.groupby('intent')['success'].mean().sort_values(ascending=False)\\n\",\n    \"sns.barplot(x=success_rate.index, y=success_rate.values, palette='viridis')\\n\",\n    \"plt.title('Success Rate per Intent')\\n\",\n    \"plt.xlabel('Intent')\\n\",\n    \"plt.ylabel('Success Rate')\\n\",\n    \"plt.xticks(rotation=45, ha='right')\\n\",\n    \"plt.ylim(0, 1)\\n\",\n    \"plt.tight_layout()\\n\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 2.4 Command Length Analysis\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"df['command_length'] = df['command_text'].apply(len)\\n\",\n    \"\\n\",\n    \"plt.figure(figsize=(12, 5))\\n\",\n    \"\\n\",\n    \"plt.subplot(1, 2, 1)\\n\",\n    \"sns.histplot(df['command_length'], kde=True, bins=20)\\n\",\n    \"plt.title('Distribution of Command Length')\\n\",\n    \"plt.xlabel('Command Length (characters)')\\n\",\n    \"plt.ylabel('Frequency')\\n\",\n    \"\\n\",\n    \"plt.subplot(1, 2, 2)\\n\",\n    \"sns.scatterplot(data=df, x='command_length', y='response_time_ms', alpha=0.5)\\n\",\n    \"plt.title('Response Time vs. Command Length')\\n\",\n    \"plt.xlabel('Command Length (characters)')\\n\",\n    \"plt.ylabel('Response Time (ms)')\\n\",\n    \"\\n\",\n    \"plt.tight_layout()\\n\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 2.5 Confirmation Analysis (for 'file_delete')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"delete_df = df[df['intent'] == 'file_delete'].copy()\\n\",\n    \"\\n\",\n    \"if not delete_df.empty:\\n\",\n    \"    # Convert nullable boolean to object/string for crosstab/countplot if needed, handling NA\\n\",\n    \"    delete_df['confirmation_given_str'] = delete_df['confirmation_given'].astype(str)\\n\",\n    \"    \\n\",\n    \"    plt.figure(figsize=(12, 5))\\n\",\n    \"    \\n\",\n    \"    plt.subplot(1, 2, 1)\\n\",\n    \"    sns.countplot(data=delete_df, x='confirmation_given_str', hue='success', palette='coolwarm')\\n\",\n    \"    plt.title('Confirmation Given vs. Final Success (for file_delete)')\\n\",\n    \"    plt.xlabel('Confirmation Given (True/False/<NA>)')\\n\",\n    \"    plt.ylabel('Count')\\n\",\n    \"    plt.legend(title='Success')\\n\",\n    \"\\n\",\n    \"    # Crosstab requires non-NA values usually, let's fill NA for visualization purposes if needed\\n\",\n    \"    # Or analyze directly\\n\",\n    \"    print(\\\"\\\\nConfirmation Status for 'file_delete' intent:\\\")\\n\",\n    \"    print(delete_df[['confirmation_required', 'confirmation_given', 'success']].value_counts(dropna=False))\\n\",\n    \"    \\n\",\n    \"    # Example: Crosstab of confirmation given vs success (only where confirmation was applicable)\\n\",\n    \"    confirmed_subset = delete_df.dropna(subset=['confirmation_given'])\\n\",\n    \"    if not confirmed_subset.empty:\\n\",\n    \"        ct = pd.crosstab(confirmed_subset['confirmation_given'], confirmed_subset['success'])\\n\",\n    \"        plt.subplot(1, 2, 2)\\n\",\n    \"        sns.heatmap(ct, annot=True, fmt='d', cmap='coolwarm')\\n\",\n    \"        plt.title('Heatmap: Confirmation Given vs Success')\\n\",\n    \"        plt.xlabel('Success')\\n\",\n    \"        plt.ylabel('Confirmation Given')\\n\",\n    \"    else:\\n\",\n    \"        print(\\\"\\\\nNo records where confirmation was given/denied (all NA or empty subset).\\\")\\n\",\n    \"\\n\",\n    \"    plt.tight_layout()\\n\",\n    \"    plt.show()\\n\",\n    \"else:\\n\",\n    \"    print(\\\"No 'file_delete' intents found in the dataset.\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 2.6 Activity Over Time\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"df.set_index('timestamp', inplace=True)\\n\",\n    \"plt.figure(figsize=(14, 6))\\n\",\n    \"df.resample('D')['command_text'].count().plot()\\n\",\n    \"plt.title('Number of Commands Per Day')\\n\",\n    \"plt.xlabel('Date')\\n\",\n    \"plt.ylabel('Number of Commands')\\n\",\n    \"plt.tight_layout()\\n\",\n    \"plt.show()\\n\",\n    \"df.reset_index(inplace=True) # Reset index after resampling\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 3. Statistical Analysis\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 3.1 Correlation Analysis (Numerical Features)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"numerical_cols = ['response_time_ms', 'command_length']\\n\",\n    \"correlation_matrix = df[numerical_cols].corr()\\n\",\n    \"\\n\",\n    \"plt.figure(figsize=(6, 4))\\n\",\n    \"sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\\n\",\n    \"plt.title('Correlation Matrix of Numerical Features')\\n\",\n    \"plt.show()\\n\",\n    \"\\n\",\n    \"print(\\\"\\\\nCorrelation Matrix:\\\")\\n\",\n    \"display(correlation_matrix)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 3.2 ANOVA: Response Time across Intents\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Check if response times differ significantly across intents\\n\",\n    \"intents_list = df['intent'].unique()\\n\",\n    \"grouped_data = [df['response_time_ms'][df['intent'] == intent] for intent in intents_list]\\n\",\n    \"\\n\",\n    \"if len(intents_list) > 1:\\n\",\n    \"    f_val, p_val = stats.f_oneway(*grouped_data)\\n\",\n    \"    print(f\\\"\\\\nANOVA test for response_time_ms across intents:\\\")\\n\",\n    \"    print(f\\\"F-statistic: {f_val:.4f}\\\")\\n\",\n    \"    print(f\\\"P-value: {p_val:.4g}\\\")\\n\",\n    \"    if p_val < 0.05:\\n\",\n    \"        print(\\\"Result: There is a statistically significant difference in mean response times between at least two intents (p < 0.05).\\\")\\n\",\n    \"    else:\\n\",\n    \"        print(\\\"Result: There is no statistically significant difference in mean response times across intents (p >= 0.05).\\\")\\n\",\n    \"else:\\n\",\n    \"    print(\\\"\\\\nANOVA requires more than one group (intent) to compare.\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 3.3 Chi-Squared Test: Intent vs. Success\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Check if there's an association between command intent and success rate\\n\",\n    \"contingency_table = pd.crosstab(df['intent'], df['success'])\\n\",\n    \"\\n\",\n    \"print(\\\"\\\\nContingency Table (Intent vs. Success):\\\")\\n\",\n    \"display(contingency_table)\\n\",\n    \"\\n\",\n    \"if contingency_table.shape[0] > 1 and contingency_table.shape[1] > 1:\\n\",\n    \"    chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\\n\",\n    \"    print(f\\\"\\\\nChi-Squared Test for Intent vs. Success:\\\")\\n\",\n    \"    print(f\\\"Chi2 Statistic: {chi2:.4f}\\\")\\n\",\n    \"    print(f\\\"P-value: {p:.4g}\\\")\\n\",\n    \"    print(f\\\"Degrees of Freedom: {dof}\\\")\\n\",\n    \"    #print(\\\"Expected Frequencies:\\\")\\n\",\n    \"    #print(expected)\\n\",\n    \"    if p < 0.05:\\n\",\n    \"        print(\\\"Result: There is a statistically significant association between command intent and success (p < 0.05).\\\")\\n\",\n    \"    else:\\n\",\n    \"        print(\\\"Result: There is no statistically significant association between command intent and success (p >= 0.05).\\\")\\n\",\n    \"else:\\n\",\n    \"     print(\\\"\\\\nChi-Squared test requires at least 2 intents and 2 outcomes (success/fail).\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 4. Feature Engineering Experiments\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# We already created 'command_length'\\n\",\n    \"# Add 'word_count'\\n\",\n    \"df['word_count'] = df['command_text'].apply(lambda x: len(x.split()))\\n\",\n    \"\\n\",\n    \"# Add binary features for keywords\\n\",\n    \"df['has_delete'] = df['command_text'].str.contains('delete|remove|erase|get rid of', case=False, regex=True)\\n\",\n    \"df['has_create'] = df['command_text'].str.contains('create|make|generate', case=False, regex=True)\\n\",\n    \"df['has_list'] = df['command_text'].str.contains('list|show me|what files', case=False, regex=True)\\n\",\n    \"df['has_search'] = df['command_text'].str.contains('search|what is|find|look up', case=False, regex=True)\\n\",\n    \"\\n\",\n    \"print(\\\"DataFrame with new features:\\\")\\n\",\n    \"display(df[['command_text', 'command_length', 'word_count', 'has_delete', 'has_create', 'has_list', 'has_search']].head())\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Analyze new features\\n\",\n    \"print(\\\"\\\\nWord Count Distribution:\\\")\\n\",\n    \"plt.figure(figsize=(8, 4))\\n\",\n    \"sns.histplot(df['word_count'], bins=15, kde=True)\\n\",\n    \"plt.title('Distribution of Word Count in Commands')\\n\",\n    \"plt.xlabel('Word Count')\\n\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"print(\\\"\\\\nKeyword Feature Counts:\\\")\\n\",\n    \"keyword_cols = ['has_delete', 'has_create', 'has_list', 'has_search']\\n\",\n    \"print(df[keyword_cols].sum())\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 5. Initial Model Testing (Intent Classification)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 5.1 Prepare Data for Modeling\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# Features: command_text\\n\",\n    \"# Target: intent\\n\",\n    \"X = df['command_text']\\n\",\n    \"y = df['intent']\\n\",\n    \"\\n\",\n    \"# Split data\\n\",\n    \"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\\n\",\n    \"\\n\",\n    \"print(f\\\"Training set size: {len(X_train)}\\\")\\n\",\n    \"print(f\\\"Test set size: {len(X_test)}\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 5.2 Feature Extraction (TF-IDF)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\\n\",\n    \"\\n\",\n    \"X_train_tfidf = vectorizer.fit_transform(X_train)\\n\",\n    \"X_test_tfidf = vectorizer.transform(X_test)\\n\",\n    \"\\n\",\n    \"print(f\\\"Shape of TF-IDF matrix (Train): {X_train_tfidf.shape}\\\")\\n\",\n    \"print(f\\\"Shape of TF-IDF matrix (Test): {X_test_tfidf.shape}\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 5.3 Train and Evaluate Naive Bayes Model\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"nb_model = MultinomialNB()\\n\",\n    \"nb_model.fit(X_train_tfidf, y_train)\\n\",\n    \"\\n\",\n    \"y_pred_nb = nb_model.predict(X_test_tfidf)\\n\",\n    \"\\n\",\n    \"accuracy_nb = accuracy_score(y_test, y_pred_nb)\\n\",\n    \"print(f\\\"Naive Bayes Accuracy: {accuracy_nb:.4f}\\\\n\\\")\\n\",\n    \"\\n\",\n    \"print(\\\"Naive Bayes Classification Report:\\\")\\n\",\n    \"print(classification_report(y_test, y_pred_nb))\\n\",\n    \"\\n\",\n    \"print(\\\"Naive Bayes Confusion Matrix:\\\")\\n\",\n    \"cm_nb = confusion_matrix(y_test, y_pred_nb, labels=nb_model.classes_)\\n\",\n    \"plt.figure(figsize=(8, 6))\\n\",\n    \"sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues', xticklabels=nb_model.classes_, yticklabels=nb_model.classes_)\\n\",\n    \"plt.title('Naive Bayes Confusion Matrix')\\n\",\n    \"plt.xlabel('Predicted Label')\\n\",\n    \"plt.ylabel('True Label')\\n\",\n    \"plt.show()\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 5.4 Train and Evaluate Logistic Regression Model\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"logreg_model = LogisticRegression(max_iter=1000, random_state=42)\\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}