{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Operator Assistant - Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Other project-related libraries (might not be used directly in training but are part of the project context)\n",
        "import speech_recognition as sr \n",
        "import pyttsx3\n",
        "import shutil\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from dotenv import load_dotenv\n",
        "import sounddevice # or import pyaudio\n",
        "\n",
        "# Load environment variables (if any API keys are needed later)\n",
        "load_dotenv()\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate loading data from a project module or file\n",
        "# In a real scenario, this would load data from a CSV, JSON, or database\n",
        "def load_simulated_data():\n",
        "    \"\"\"Creates a simulated dataset of commands and intents.\"\"\"\n",
        "    data = {\n",
        "        'text': [\n",
        "            # File Creation\n",
        "            \"create a new file named report.txt\",\n",
        "            \"make a document called notes\",\n",
        "            \"generate an empty file project_plan.docx\",\n",
        "            \"new text file data.csv\",\n",
        "            \"touch file script.py\",\n",
        "            \n",
        "            # File Listing\n",
        "            \"list all files in the current directory\",\n",
        "            \"show me the files here\",\n",
        "            \"what files are in this folder?\",\n",
        "            \"directory listing\",\n",
        "            \"ls command\",\n",
        "            \n",
        "            # File Deletion\n",
        "            \"delete the file temp.log\",\n",
        "            \"remove old_report.txt\",\n",
        "            \"get rid of junk.dat\",\n",
        "            \"erase the document draft_v1.doc\",\n",
        "            \"rm temporary_file\",\n",
        "            \n",
        "            # Web Search\n",
        "            \"search the web for python tutorials\",\n",
        "            \"find information about machine learning\",\n",
        "            \"what is the weather today?\",\n",
        "            \"google the capital of France\",\n",
        "            \"look up the definition of AI\",\n",
        "            \"who won the world series last year?\",\n",
        "            \"search for nearby restaurants\",\n",
        "            \n",
        "            # Other/Ambiguous (Could be expanded)\n",
        "            \"hello operator\",\n",
        "            \"tell me a joke\",\n",
        "            \"what time is it?\",\n",
        "            \"open calculator\", # This might become a separate intent later\n",
        "            \"shutdown the computer\" # This needs careful handling\n",
        "        ],\n",
        "        'intent': [\n",
        "            # File Creation\n",
        "            'create_file', 'create_file', 'create_file', 'create_file', 'create_file',\n",
        "            # File Listing\n",
        "            'list_files', 'list_files', 'list_files', 'list_files', 'list_files',\n",
        "            # File Deletion\n",
        "            'delete_file', 'delete_file', 'delete_file', 'delete_file', 'delete_file',\n",
        "            # Web Search\n",
        "            'search_web', 'search_web', 'search_web', 'search_web', 'search_web', 'search_web', 'search_web',\n",
        "            # Other\n",
        "            'other', 'other', 'other', 'other', 'other'\n",
        "        ]\n",
        "    }\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Load the data\n",
        "df = load_simulated_data()\n",
        "\n",
        "# Display data info and sample\n",
        "print(\"Data Info:\")\n",
        "df.info()\n",
        "print(\"\\nData Sample:\")\n",
        "print(df.head())\n",
        "print(\"\\nIntent Distribution:\")\n",
        "print(df['intent'].value_counts())\n",
        "\n",
        "# Prepare data for modeling\n",
        "X = df['text']\n",
        "y = df['intent']\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Save the label encoder for later use during inference\n",
        "joblib.dump(label_encoder, 'label_encoder.joblib')\n",
        "print(\"\\nLabel Encoder Classes:\", label_encoder.classes_)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.25, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set size: {len(X_train)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Definition and Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a pipeline with TF-IDF Vectorizer and a Classifier (e.g., Logistic Regression)\n",
        "# We will use GridSearchCV later to choose the best classifier and its hyperparameters\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(random_state=42)),\n",
        "    ('clf', LogisticRegression(random_state=42, max_iter=1000)) # Placeholder classifier\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Hyperparameter Tuning (Grid Search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define parameter grid for GridSearchCV\n",
        "# We'll test different classifiers and their parameters, plus TF-IDF parameters\n",
        "param_grid = [\n",
        "    {\n",
        "        'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "        'tfidf__use_idf': [True, False],\n",
        "        'tfidf__norm': ['l1', 'l2'],\n",
        "        'clf': [LogisticRegression(random_state=42, max_iter=1000, solver='liblinear')],\n",
        "        'clf__C': [0.1, 1, 10, 100],\n",
        "        'clf__penalty': ['l1', 'l2']\n",
        "    },\n",
        "    {\n",
        "        'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "        'tfidf__use_idf': [True, False],\n",
        "        'tfidf__norm': ['l1', 'l2'],\n",
        "        'clf': [SVC(random_state=42, probability=True)],\n",
        "        'clf__C': [0.1, 1, 10, 100],\n",
        "        'clf__gamma': [0.1, 0.01, 0.001],\n",
        "        'clf__kernel': ['linear', 'rbf']\n",
        "    },\n",
        "     {\n",
        "        'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
        "        'tfidf__use_idf': [True, False],\n",
        "        'tfidf__norm': ['l1', 'l2'],\n",
        "        'clf': [MultinomialNB()],\n",
        "        'clf__alpha': [0.1, 0.5, 1.0]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Perform Grid Search with Cross-Validation (CV)\n",
        "# Using accuracy as the scoring metric, cv=3 for faster execution on small dataset\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "\n",
        "print(\"Starting Grid Search...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters and best score\n",
        "print(\"\\nGrid Search Finished.\")\n",
        "print(f\"Best Score (Accuracy): {grid_search.best_score_:.4f}\")\n",
        "print(\"Best Parameters:\")\n",
        "best_params = grid_search.best_params_\n",
        "for param_name in sorted(best_params.keys()):\n",
        "    print(f\"  {param_name}: {best_params[param_name]}\")\n",
        "\n",
        "# Get the best estimator\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the best model on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Decode predictions and true labels for reporting\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
        "y_test_labels = label_encoder.inverse_transform(y_test)\n",
        "target_names = label_encoder.classes_\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report on Test Set:\")\n",
        "print(classification_report(y_test_labels, y_pred_labels, target_names=target_names))\n",
        "\n",
        "# Calculate overall accuracy\n",
        "accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
        "print(f\"Overall Accuracy on Test Set: {accuracy:.4f}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test_labels, y_pred_labels, labels=target_names)\n",
        "cm_df = pd.DataFrame(cm, index=target_names, columns=target_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Results Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix on Test Set')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Save the Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained pipeline (including vectorizer and classifier)\n",
        "model_filename = 'intent_classifier_pipeline.joblib'\n",
        "joblib.dump(best_model, model_filename)\n",
        "print(f\"\\nBest model saved to {model_filename}\")\n",
        "\n",
        "# Also save the label encoder classes for reference\n",
        "label_map_filename = 'label_encoder_classes.json'\n",
        "label_map = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
        "with open(label_map_filename, 'w') as f:\n",
        "    json.dump(label_map, f, indent=4)\n",
        "print(f\"Label mapping saved to {label_map_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Example Prediction (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model and label encoder (as if in a separate application)\n",
        "loaded_model = joblib.load('intent_classifier_pipeline.joblib')\n",
        "loaded_label_encoder = joblib.load('label_encoder.joblib')\n",
        "\n",
        "# Example new commands\n",
        "new_commands = [\n",
        "    \"what files do I have?\",\n",
        "    \"make a shopping list file\",\n",
        "    \"search for python documentation\",\n",
        "    \"delete the image screenshot.png\",\n",
        "    \"good morning operator\"\n",
        "]\n",
        "\n",
        "# Predict intents for new commands\n",
        "predicted_encoded = loaded_model.predict(new_commands)\n",
        "predicted_labels = loaded_label_encoder.inverse_transform(predicted_encoded)\n",
        "\n",
        "print(\"\\nExample Predictions:\")\n",
        "for command, intent in zip(new_commands, predicted_labels):\n",
        "    print(f\"  Command: '{command}' -> Predicted Intent: '{intent}'\")\n",
        "    \n",
        "# Example of getting prediction probabilities (if supported by the best classifier, e.g., LogisticRegression, SVC with probability=True)\n",
        "if hasattr(loaded_model.named_steps['clf'], 'predict_proba'):\n",
        "    print(\"\\nExample Prediction Probabilities:\")\n",
        "    probabilities = loaded_model.predict_proba([new_commands[0]])[0]\n",
        "    prob_map = {label: prob for label, prob in zip(loaded_label_encoder.classes_, probabilities)}\n",
        "    print(f\"  Command: '{new_commands[0]}'\")\n",
        "    for intent, prob in sorted(prob_map.items(), key=lambda item: item[1], reverse=True):\n",
        "         print(f\"    Intent: {intent:<15} Probability: {prob:.4f}\")\n",
        "else:\n",
        "    print(\"\\nPredict_proba not available for the chosen best classifier.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}